{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load experience and train the behavioral cloning agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_coach.agents.bc_agent import BCAgentParameters\n",
    "from rl_coach.base_parameters import VisualizationParameters, TaskParameters\n",
    "from rl_coach.core_types import TrainingSteps, EnvironmentSteps\n",
    "from rl_coach.environments.gym_environment import Atari\n",
    "from rl_coach.graph_managers.basic_rl_graph_manager import BasicRLGraphManager\n",
    "from rl_coach.graph_managers.graph_manager import SimpleSchedule\n",
    "\n",
    "\n",
    "agent_params = BCAgentParameters()\n",
    "agent_params.memory.load_memory_from_file_path = 'experience_breakout.p'\n",
    "agent_params.algorithm.num_consecutive_playing_steps = EnvironmentSteps(0)\n",
    "env_params = Atari(level='BreakoutDeterministic-v4')\n",
    "\n",
    "# Create graph manager\n",
    "graph_manager = BasicRLGraphManager(agent_params=agent_params, env_params=env_params,\n",
    "                                              schedule_params=SimpleSchedule(), vis_params=VisualizationParameters())\n",
    "\n",
    "# Set the checkpoint save directory\n",
    "task_parameters = TaskParameters(framework_type=\"tensorflow\",\n",
    "                                         save_checkpoint_secs=10)\n",
    "task_parameters.__dict__['save_checkpoint_dir'] = './checkpoints'\n",
    "graph_manager.create_graph(task_parameters)\n",
    "\n",
    "graph_manager.train_and_act(TrainingSteps(3000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_manager.evaluate(EnvironmentSteps(1000), keep_networks_in_sync=True)\n",
    "graph_manager.save_checkpoint()\n",
    "#print(graph_manager.top_level_manager.agents['agent'].networks['main'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained model into a policy gradients agent and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_coach.agents.policy_gradients_agent import PolicyGradientsAgentParameters\n",
    "from rl_coach.filters.filter import OutputFilter\n",
    "from rl_coach.environments.gym_environment import AtariInputFilter\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Workaround to allow running a second evaluation with the same graph manager\n",
    "tf.reset_default_graph()\n",
    "graph_manager.graph_creation_time = None\n",
    "\n",
    "agent_params = PolicyGradientsAgentParameters()\n",
    "agent_params.algorithm.discount = 0.99\n",
    "agent_params.algorithm.apply_gradients_every_x_episodes = 5\n",
    "agent_params.algorithm.num_steps_between_gradient_updates = 20000\n",
    "\n",
    "agent_params.network_wrappers['main'].optimizer_type = 'Adam'\n",
    "agent_params.network_wrappers['main'].learning_rate = 0.0005\n",
    "\n",
    "agent_params.input_filter = AtariInputFilter()\n",
    "agent_params.output_filter = OutputFilter()\n",
    "\n",
    "graph_manager.agent_params = agent_params\n",
    "\n",
    "# Set the checkpoint restore directory\n",
    "task_parameters.__dict__['checkpoint_restore_dir'] = './checkpoints'\n",
    "task_parameters.__dict__['save_checkpoint_secs'] = 600\n",
    "graph_manager.create_graph(task_parameters)\n",
    "\n",
    "graph_manager.restore_checkpoint()\n",
    "graph_manager.train_and_act(TrainingSteps(100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_manager.evaluate(EnvironmentSteps(1000), keep_networks_in_sync=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
